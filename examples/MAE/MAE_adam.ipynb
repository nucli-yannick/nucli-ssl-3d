{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7105970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "[]\n",
      "['unet', 'encoder_unet']\n"
     ]
    }
   ],
   "source": [
    "from nucli_train.data_management.builders import build_data\n",
    "from nucli_train.models.builders import build_model, MODEL_REGISTRY, MODEL_BUILDERS_REGISTRY\n",
    "\n",
    "from nucli_train.training import Trainer\n",
    "from nucli_train.nets.builders import NETWORK_REGISTRY, ARCHITECTURE_BUILDERS_REGISTRY\n",
    "\n",
    "print(list(NETWORK_REGISTRY._dict.keys()))\n",
    "print(list(ARCHITECTURE_BUILDERS_REGISTRY._dict.keys()))\n",
    "\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847f6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adammesbahi/miniforge3/envs/nnssl/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968a3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.preprocess.preprocessor import PreprocessorBlosc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60414971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAEPreprocessor(PreprocessorBlosc2): \n",
    "    def __init__(self, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def exclude_condition(self, nifti_filename):\n",
    "        return nifti_filename.endswith(\"0000.nii.gz\") \n",
    "    \n",
    "    def identify_tracer(self, nifti_filename):\n",
    "        if \"fdg\" in nifti_filename:\n",
    "            return \"fdg\"\n",
    "        elif \"psma\" in nifti_filename:\n",
    "            return \"psma\"\n",
    "        return \"unknown\"\n",
    "        \n",
    "    \n",
    "    def identify_center(self, nifti_filename):\n",
    "        return \"autopet_center\"\n",
    "    \n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    \"dataset_name\": \"autopet_2024\",\n",
    "    \"dataset_path\": \"/Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024\",\n",
    "    \"exp_name\": \"MAE_adam_experiment\",\n",
    "    \"nifti_input_rootdir\": \"/Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/imagesTr\",\n",
    "    \"nifti_target_rootdir\": None,\n",
    "    \"percentage_dataset\": 1.0,\n",
    "    \"train_val_percentage\": 0.8,\n",
    "    \"spacing\": (1.0, 1.0, 1.0),\n",
    "    \"batch_size_train\": 2,\n",
    "    \"batch_size_val\": 2,\n",
    "    \"num_workers_train\": 1,\n",
    "    \"num_workers_val\": 1,\n",
    "    \"global_eval_interval\": 10,\n",
    "    \"patch_size\": (64, 64, 64),\n",
    "    \"shuffle_pick\": True,\n",
    "    \"validation_evaluator\": \"save-preds-MIM\", \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_adam_experiment\n",
      "Compressed fdg_04606080a0_02-20-2003-NA-PET-CT Ganzkoerper  primaer mit KM-22538_0001.nii.gz to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/input/fdg_04606080a0_02-20-2003-NA-PET-CT Ganzkoerper  primaer mit KM-22538_0001\n",
      "Shape of the volume: (400, 400, 284)\n",
      "Adam -- -- -- Number of valid centers: 1045018\n",
      "saved coordinates to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/coords/fdg_04606080a0_02-20-2003-NA-PET-CT Ganzkoerper  primaer mit KM-22538_0001.npy\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "Compressed fdg_048981112f_07-31-2005-NA-Unspecified CT ABDOMEN-50330_0001.nii.gz to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/input/fdg_048981112f_07-31-2005-NA-Unspecified CT ABDOMEN-50330_0001\n",
      "Shape of the volume: (400, 400, 568)\n",
      "Adam -- -- -- Number of valid centers: 1519204\n",
      "saved coordinates to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/coords/fdg_048981112f_07-31-2005-NA-Unspecified CT ABDOMEN-50330_0001.npy\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "Compressed fdg_0b57b247b6_05-02-2002-NA-PET-CT Ganzkoerper  primaer mit KM-42966_0001.nii.gz to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/input/fdg_0b57b247b6_05-02-2002-NA-PET-CT Ganzkoerper  primaer mit KM-42966_0001\n",
      "Shape of the volume: (400, 400, 326)\n",
      "Adam -- -- -- Number of valid centers: 1567207\n",
      "saved coordinates to /Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/blosc2_64_64_64/training/autopet_2024/autopet_center/fdg/coords/fdg_0b57b247b6_05-02-2002-NA-PET-CT Ganzkoerper  primaer mit KM-42966_0001.npy\n",
      "\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "my_preprocessor = MAEPreprocessor(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac7bc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.models.image_translation import ImageTranslationModel\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "\n",
    "def create_blocky_mask(tensor_size, block_size, sparsity_factor=0.75, rng_seed: None | int = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function creates the mask used in MAE. \n",
    "    The image returned is not the masked image but the mask we will multiply by the image. \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the size of the smaller mask\n",
    "    small_mask_size = tuple(size // block_size for size in tensor_size)\n",
    "\n",
    "    # Create the smaller mask\n",
    "    flat_mask = torch.ones(np.prod(small_mask_size))\n",
    "    n_masked = int(sparsity_factor * flat_mask.shape[0])\n",
    "    if rng_seed is None:\n",
    "        mask_indices = torch.randperm(flat_mask.shape[0])[:n_masked]\n",
    "    else:\n",
    "        gen = torch.Generator.manual_seed(rng_seed)\n",
    "        mask_indices = torch.randperm(flat_mask.shape[0], generator=gen)[:n_masked]\n",
    "    flat_mask[mask_indices] = 0\n",
    "    small_mask = torch.reshape(flat_mask, small_mask_size)\n",
    "    return small_mask\n",
    "\n",
    "\n",
    "class MIM(ImageTranslationModel):\n",
    "    @staticmethod\n",
    "    def mask_creation(\n",
    "        batch_size: int,\n",
    "        patch_size: tuple[int, int, int],\n",
    "        mask_percentage: float,\n",
    "        rng_seed: int | None = None,\n",
    "        block_size: int = 16,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Creates a masking tensor with 1s (indicating no masking) and 0s (indicating masking).\n",
    "        The mask has to be of same size like the input data (batch_size, 1, x, y, z).\n",
    "\n",
    "        :param batch_size: batch size during training\n",
    "        :param patch_size: The 3D shape information for the input patch.\n",
    "        :param mask_percentage: percentage of the patch that should be masked\n",
    "        :param block_size: size of the blocks that should be masked\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "\n",
    "        sparsity_factor = mask_percentage\n",
    "        mask = [create_blocky_mask(patch_size, block_size, sparsity_factor) for _ in range(batch_size)]\n",
    "        mask = torch.stack(mask)[:, None, ...]  # Add channel dimension\n",
    "        return mask\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        print(batch.keys())\n",
    "        data = batch['input'].cuda()\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "        mask = self.mask_creation(data.shape[0], [128, 128, 128], 0.75).cuda()\n",
    "        \n",
    "        rep_D, rep_H, rep_W = (\n",
    "            data.shape[2] // mask.shape[2],\n",
    "            data.shape[3] // mask.shape[3],\n",
    "            data.shape[4] // mask.shape[4],\n",
    "        )\n",
    "\n",
    "        mask = mask.repeat_interleave(rep_D, dim=2).repeat_interleave(rep_H, dim=3).repeat_interleave(rep_W, dim=4)\n",
    "        masked_data = data * mask\n",
    "\n",
    "        output = self.network(masked_data)\n",
    "\n",
    "        losses = self.get_losses(output, data)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        data = batch['input'].cuda()\n",
    "\n",
    "        mask = self.mask_creation(data.shape[0], [128, 128, 128], 0.75).cuda()\n",
    "        \n",
    "        rep_D, rep_H, rep_W = (\n",
    "            data.shape[2] // mask.shape[2],\n",
    "            data.shape[3] // mask.shape[3],\n",
    "            data.shape[4] // mask.shape[4],\n",
    "        )\n",
    "\n",
    "        mask = mask.repeat_interleave(rep_D, dim=2).repeat_interleave(rep_H, dim=3).repeat_interleave(rep_W, dim=4)\n",
    "        masked_data = data * mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            output = self.network(masked_data)\n",
    "\n",
    "        losses = self.get_losses(output, data)\n",
    "\n",
    "        outputs = output.detach().cpu() # should remove this at some point. Going to cpu only makes sense if we want to save images\n",
    "        targets = data.detach().cpu()\n",
    "        inputs = masked_data.detach().cpu()\n",
    "\n",
    "        metrics = self.get_metrics(outputs, targets, inputs)\n",
    "\n",
    "        return {\"losses\": losses, \"metrics\": metrics, \"predictions\": outputs, 'input' : inputs, 'original' : targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8c64895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "from nucli_train.nets import build_network\n",
    "from nucli_train.models.losses import build_losses\n",
    "\n",
    "@MODEL_BUILDERS_REGISTRY.register('MAE')\n",
    "def build_MAE(cfg):\n",
    "    network = build_network(cfg['args']['network'])\n",
    "\n",
    "    losses = build_losses(cfg['args']['losses'])    \n",
    "\n",
    "    return MIM(network, loss_functions=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe4a906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "from nucli_train.val.evaluators import EVALUATORS_REGISTRY\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@EVALUATORS_REGISTRY.register('save-preds-MIM')\n",
    "class SavePredictionMIM:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "    def evaluate_batch(self, model_output, batch):\n",
    "        self.masked, self.original, self.prediction = model_output['input'], model_output['original'], model_output['predictions']\n",
    "    def log_epoch(self, epoch):\n",
    "        fig, axs = plt.subplots(min(self.masked.shape[0], 3), 3)\n",
    "        for i in range(min(self.masked.shape[0], 3)):\n",
    "            axs[i, 0].imshow(self.masked[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 0].set_axis_off()\n",
    "            axs[i, 1].imshow(self.prediction[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 1].set_axis_off()\n",
    "            axs[i, 2].imshow(self.original[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 2].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        mlflow.log_figure(fig, artifact_file=f\"{self.dataset_name}/predictions/epoch_{epoch}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcc738c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_translation': <function build_image_translation_model at 0x174157490>, 'mae': <function build_MAE at 0x17440b2e0>}\n",
      "MAE\n",
      "{'unet': <function build_unet_from_cfg at 0x17411d480>, 'encoder_unet': <function build_encoder_unet_from_cfg at 0x17411d750>}\n",
      "UNet\n",
      "{'perceptuallossmedicalnet': <class 'nucli_train.models.losses.perceptual.PerceptualLoss3D'>, 'l1loss': <function l1_loss at 0x17411caf0>, 'vocoloss': <function voco_loss at 0x17411cb80>}\n",
      "L1Loss\n"
     ]
    }
   ],
   "source": [
    "model = build_model('/Users/adammesbahi/Desktop/nucli-ssl/nucli-ssl/examples/MAE/MIM_model.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74335e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/nucli_train/MAE_adam_experiment/autopet_2024/main.yaml\n"
     ]
    }
   ],
   "source": [
    "from nucli_train.data_management.builders import build_data\n",
    "import nucli_train.data_management.transformations \n",
    "print(my_preprocessor.nucli_train_path + \"/main.yaml\")\n",
    "\n",
    "train_data, val_loaders = build_data(my_preprocessor.nucli_train_path + \"/main.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043fe8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'MIM'. Detailed error Yaml file './experiments/MIM/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 356, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 454, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1595, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1588, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/adammesbahi/miniforge3/envs/nnssl/lib/python3.10/site-packages/mlflow/utils/yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './experiments/MIM/meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "trainer = Trainer(model, train_data=train_data, val_loaders=val_loaders, run_name='base-deeper', experiment_name='MIM', save_interval=50, model_cfg_path='/Users/adammesbahi/Desktop/nucli-ssl/nucli-ssl/examples/MAE/MIM_model.yaml', data_cfg_path=my_preprocessor.nucli_train_path + \"/main.yaml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "008c98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/16 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Trainer.run.<locals>.seed_worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/nucli-ssl/nucli-ssl/src/nucli_train/training/trainer.py:160\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    153\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m    154\u001b[0m loader \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m    155\u001b[0m     train_loader,\n\u001b[1;32m    156\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m )\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp:\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:491\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:422\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1139\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nnssl/lib/python3.10/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'Trainer.run.<locals>.seed_worker'"
     ]
    }
   ],
   "source": [
    "trainer.run(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55155d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc3ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae1fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79a246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a26fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1df9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6e419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9a5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
