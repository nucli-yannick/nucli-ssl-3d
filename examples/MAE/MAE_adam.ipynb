{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7105970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['unet', 'decoder']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ybr/projects/nucli-train/src/nucli_train/models/losses/segmentation.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)  # keep Dice in fp32 for stability\n"
     ]
    }
   ],
   "source": [
    "from nucli_train.data_management.builders import build_data\n",
    "from nucli_train.models.builders import build_model, MODEL_REGISTRY, MODEL_BUILDERS_REGISTRY\n",
    "\n",
    "from nucli_train.training import Trainer\n",
    "from nucli_train.nets.builders import NETWORK_REGISTRY, ARCHITECTURE_BUILDERS_REGISTRY\n",
    "\n",
    "print(list(NETWORK_REGISTRY._dict.keys()))\n",
    "print(list(ARCHITECTURE_BUILDERS_REGISTRY._dict.keys()))\n",
    "\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847f6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ybr/miniconda3/envs/ssl-3d/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968a3c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nucli_train.data_management.create_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mssl_3d\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreprocessorBlosc2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ssl-3d/src/ssl_3d/preprocess/preprocessor.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mssl_3d\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpotential_centers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_one_case\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnucli_train\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_management\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcreate_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_blosc\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mruamel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01myaml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YAML\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nucli_train.data_management.create_dataset'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from ssl_3d.preprocess.preprocessor import PreprocessorBlosc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60414971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAEPreprocessor(PreprocessorBlosc2): \n",
    "    def __init__(self, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def exclude_condition(self, nifti_filename):\n",
    "        return nifti_filename.endswith(\"0000.nii.gz\") \n",
    "    \n",
    "    def identify_tracer(self, nifti_filename):\n",
    "        if \"fdg\" in nifti_filename:\n",
    "            return \"fdg\"\n",
    "        elif \"psma\" in nifti_filename:\n",
    "            return \"psma\"\n",
    "        return \"unknown\"\n",
    "        \n",
    "    \n",
    "    def identify_center(self, nifti_filename):\n",
    "        return \"autopet_center\"\n",
    "    \n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    \"dataset_name\": \"autopet_2024\",\n",
    "    \"dataset_path\": \"/Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024\",\n",
    "    \"exp_name\": \"MAE_adam_experiment\",\n",
    "    \"nifti_input_rootdir\": \"/Users/adammesbahi/Desktop/nucli-ssl/data/autopet_2024/imagesTr\",\n",
    "    \"nifti_target_rootdir\": None,\n",
    "    \"percentage_dataset\": 1.0,\n",
    "    \"train_val_percentage\": 0.8,\n",
    "    \"spacing\": (1.0, 1.0, 1.0),\n",
    "    \"batch_size_train\": 2,\n",
    "    \"batch_size_val\": 2,\n",
    "    \"num_workers_train\": 1,\n",
    "    \"num_workers_val\": 1,\n",
    "    \"global_eval_interval\": 10,\n",
    "    \"patch_size\": (64, 64, 64),\n",
    "    \"shuffle_pick\": True,\n",
    "    \"validation_evaluator\": \"save-preds-MIM\", \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preprocessor = MAEPreprocessor(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.models.image_translation import ImageTranslationModel\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "\n",
    "def create_blocky_mask(tensor_size, block_size, sparsity_factor=0.75, rng_seed: None | int = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function creates the mask used in MAE. \n",
    "    The image returned is not the masked image but the mask we will multiply by the image. \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the size of the smaller mask\n",
    "    small_mask_size = tuple(size // block_size for size in tensor_size)\n",
    "\n",
    "    # Create the smaller mask\n",
    "    flat_mask = torch.ones(np.prod(small_mask_size))\n",
    "    n_masked = int(sparsity_factor * flat_mask.shape[0])\n",
    "    if rng_seed is None:\n",
    "        mask_indices = torch.randperm(flat_mask.shape[0])[:n_masked]\n",
    "    else:\n",
    "        gen = torch.Generator.manual_seed(rng_seed)\n",
    "        mask_indices = torch.randperm(flat_mask.shape[0], generator=gen)[:n_masked]\n",
    "    flat_mask[mask_indices] = 0\n",
    "    small_mask = torch.reshape(flat_mask, small_mask_size)\n",
    "    return small_mask\n",
    "\n",
    "\n",
    "class MIM(ImageTranslationModel):\n",
    "    @staticmethod\n",
    "    def mask_creation(\n",
    "        batch_size: int,\n",
    "        patch_size: tuple[int, int, int],\n",
    "        mask_percentage: float,\n",
    "        rng_seed: int | None = None,\n",
    "        block_size: int = 16,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Creates a masking tensor with 1s (indicating no masking) and 0s (indicating masking).\n",
    "        The mask has to be of same size like the input data (batch_size, 1, x, y, z).\n",
    "\n",
    "        :param batch_size: batch size during training\n",
    "        :param patch_size: The 3D shape information for the input patch.\n",
    "        :param mask_percentage: percentage of the patch that should be masked\n",
    "        :param block_size: size of the blocks that should be masked\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "\n",
    "        sparsity_factor = mask_percentage\n",
    "        mask = [create_blocky_mask(patch_size, block_size, sparsity_factor) for _ in range(batch_size)]\n",
    "        mask = torch.stack(mask)[:, None, ...]  # Add channel dimension\n",
    "        return mask\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        print(batch.keys())\n",
    "        data = batch['input'].cuda()\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "        mask = self.mask_creation(data.shape[0], [128, 128, 128], 0.75).cuda()\n",
    "        \n",
    "        rep_D, rep_H, rep_W = (\n",
    "            data.shape[2] // mask.shape[2],\n",
    "            data.shape[3] // mask.shape[3],\n",
    "            data.shape[4] // mask.shape[4],\n",
    "        )\n",
    "\n",
    "        mask = mask.repeat_interleave(rep_D, dim=2).repeat_interleave(rep_H, dim=3).repeat_interleave(rep_W, dim=4)\n",
    "        masked_data = data * mask\n",
    "\n",
    "        output = self.network(masked_data)\n",
    "\n",
    "        losses = self.get_losses(output, data)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        data = batch['input'].cuda()\n",
    "\n",
    "        mask = self.mask_creation(data.shape[0], [128, 128, 128], 0.75).cuda()\n",
    "        \n",
    "        rep_D, rep_H, rep_W = (\n",
    "            data.shape[2] // mask.shape[2],\n",
    "            data.shape[3] // mask.shape[3],\n",
    "            data.shape[4] // mask.shape[4],\n",
    "        )\n",
    "\n",
    "        mask = mask.repeat_interleave(rep_D, dim=2).repeat_interleave(rep_H, dim=3).repeat_interleave(rep_W, dim=4)\n",
    "        masked_data = data * mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            output = self.network(masked_data)\n",
    "\n",
    "        losses = self.get_losses(output, data)\n",
    "\n",
    "        outputs = output.detach().cpu() # should remove this at some point. Going to cpu only makes sense if we want to save images\n",
    "        targets = data.detach().cpu()\n",
    "        inputs = masked_data.detach().cpu()\n",
    "\n",
    "        metrics = self.get_metrics(outputs, targets, inputs)\n",
    "\n",
    "        return {\"losses\": losses, \"metrics\": metrics, \"predictions\": outputs, 'input' : inputs, 'original' : targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c64895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.nets import build_network\n",
    "from nucli_train.models.losses import build_losses\n",
    "\n",
    "@MODEL_BUILDERS_REGISTRY.register('MAE')\n",
    "def build_MAE(cfg):\n",
    "    network = build_network(cfg['args']['network'])\n",
    "\n",
    "    losses = build_losses(cfg['args']['losses'])    \n",
    "\n",
    "    return MIM(network, loss_functions=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.val.evaluators import EVALUATORS_REGISTRY\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@EVALUATORS_REGISTRY.register('save-preds-MIM')\n",
    "class SavePredictionMIM:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "    def evaluate_batch(self, model_output, batch):\n",
    "        self.masked, self.original, self.prediction = model_output['input'], model_output['original'], model_output['predictions']\n",
    "    def log_epoch(self, epoch):\n",
    "        fig, axs = plt.subplots(min(self.masked.shape[0], 3), 3)\n",
    "        for i in range(min(self.masked.shape[0], 3)):\n",
    "            axs[i, 0].imshow(self.masked[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 0].set_axis_off()\n",
    "            axs[i, 1].imshow(self.prediction[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 1].set_axis_off()\n",
    "            axs[i, 2].imshow(self.original[i, 0, :, 32, :].cpu().numpy(), cmap='gray', vmin=0.0, vmax=2.0)\n",
    "            axs[i, 2].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        mlflow.log_figure(fig, artifact_file=f\"{self.dataset_name}/predictions/epoch_{epoch}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc738c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model('/Users/adammesbahi/Desktop/nucli-ssl/nucli-ssl/examples/MAE/MIM_model.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74335e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucli_train.data_management.builders import build_data\n",
    "import nucli_train.data_management.transformations \n",
    "print(my_preprocessor.nucli_train_path + \"/main.yaml\")\n",
    "\n",
    "train_data, val_loaders = build_data(my_preprocessor.nucli_train_path + \"/main.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fe8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "trainer = Trainer(model, train_data=train_data, val_loaders=val_loaders, run_name='base-deeper', experiment_name='MIM', save_interval=50, model_cfg_path='/Users/adammesbahi/Desktop/nucli-ssl/nucli-ssl/examples/MAE/MIM_model.yaml', data_cfg_path=my_preprocessor.nucli_train_path + \"/main.yaml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55155d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc3ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae1fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79a246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a26fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1df9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6e419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9a5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
